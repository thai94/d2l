{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9.2.long_short_term_memory_lstm_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcu8atU31NMC/Dlwe/SU/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thai94/d2l/blob/main/9.modern_recurrent_neural_networks/9_2_long_short_term_memory_lstm_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rGaybdXuO4Cw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import collections\n",
        "import re\n",
        "import hashlib\n",
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch import nn\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_HUB = dict()\n",
        "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
        "DATA_HUB['time_machine'] = (DATA_URL + 'timemachine.txt',\n",
        "                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
        "\n",
        "def download(name, cache_dir=os.path.join('..', 'data')):\n",
        "    \"\"\"Download a file inserted into DATA_HUB, return the local filename.\"\"\"\n",
        "    assert name in DATA_HUB, f\"{name} does not exist in {DATA_HUB}.\"\n",
        "    url, sha1_hash = DATA_HUB[name]\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        sha1 = hashlib.sha1()\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "                sha1.update(data)\n",
        "        if sha1.hexdigest() == sha1_hash:\n",
        "            return fname  # Hit cache\n",
        "    print(f'Downloading {fname} from {url}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def download_extract(name, folder=None):\n",
        "    \"\"\"Download and extract a zip/tar file.\"\"\"\n",
        "    fname = download(name)\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    elif ext in ('.tar', '.gz'):\n",
        "        fp = tarfile.open(fname, 'r')\n",
        "    else:\n",
        "        assert False, 'Only zip/tar files can be extracted.'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\n",
        "\n",
        "def download_all():\n",
        "    \"\"\"Download all files in the DATA_HUB.\"\"\"\n",
        "    for name in DATA_HUB:\n",
        "        download(name)\n",
        "\n",
        "def read_time_machine():\n",
        "    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n",
        "    with open(download('time_machine'), 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
        "\n",
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def tokenize(lines, token='word'):\n",
        "\n",
        "  if token == 'word':\n",
        "    return [line.split() for line in lines]\n",
        "  elif token == 'char':\n",
        "    return [list(line) for line in lines]\n",
        "  else:\n",
        "    print('ERROR: unknow token type: ' + token)\n",
        "\n",
        "def count_corpus(tokens):\n",
        "\n",
        "  if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "   tokens = [token for line in tokens for token in line]\n",
        "  return collections.Counter(tokens)\n",
        "\n",
        "class Vocab:\n",
        "\n",
        "  def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "\n",
        "    if tokens is None:\n",
        "      tokens = []\n",
        "    if reserved_tokens is None:\n",
        "      reserved_tokens = []\n",
        "    counter = count_corpus(tokens)\n",
        "\n",
        "    self._token_freqs = sorted(counter.items(), key = lambda x: x[1], reverse=True)\n",
        "    self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "    self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
        "    for token, freq in self._token_freqs:\n",
        "      if freq < min_freq:\n",
        "        break;\n",
        "      if token not in self.token_to_idx:\n",
        "        self.idx_to_token.append(token)\n",
        "        self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)\n",
        "  \n",
        "  def __getitem__(self, tokens):\n",
        "    if not isinstance(tokens, (list, tuple)):\n",
        "      return self.token_to_idx.get(tokens, self.unk)\n",
        "    else:\n",
        "      return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "  def to_tokens(self, indices):\n",
        "    if not isinstance(indices, (list, tuple)):\n",
        "      return self.idx_to_token[indices]\n",
        "    else:\n",
        "      return [self.to_tokens(idx) for idx in indices]\n",
        "\n",
        "  @property\n",
        "  def unk(self):\n",
        "    return 0\n",
        "\n",
        "  @property\n",
        "  def token_freqs(self):\n",
        "    return self._token_freqs\n",
        "\n",
        "\n",
        "def load_corpus_time_machine(max_tokens=-1):\n",
        "\n",
        "  lines = read_time_machine()\n",
        "  tokens = tokenize(lines, 'char')\n",
        "  vocab = Vocab(tokens)\n",
        "\n",
        "  corpus = [vocab[token] for line in tokens for token in line]\n",
        "  if max_tokens > 0:\n",
        "    corpus = corpus[:max_tokens]\n",
        "  return corpus, vocab\n",
        "\n",
        "\n",
        "def seq_data_iter_random(corpus, batch_size, num_steps):\n",
        "\n",
        "  corpos = corpus[random.randint(0, num_steps - 1):]\n",
        "  num_subseqs = (len(corpos) - 1) // num_steps\n",
        "  initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
        "  random.shuffle(initial_indices)\n",
        "\n",
        "  def data(pos):\n",
        "    return corpus[pos: pos + num_steps]\n",
        "  \n",
        "  num_batches = num_subseqs // batch_size\n",
        "\n",
        "  for i in range(0, batch_size * num_batches, batch_size):\n",
        "    initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
        "    X = [data(idx) for idx in initial_indices_per_batch]\n",
        "    Y = [data(idx + 1) for idx in initial_indices_per_batch]\n",
        "    yield torch.tensor(X), torch.tensor(Y)\n",
        "\n",
        "\n",
        "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
        "\n",
        "  offset = random.randint(0, num_steps)\n",
        "  num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
        "  Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
        "  Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
        "\n",
        "  Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
        "  num_batches = Xs.shape[1] // num_steps\n",
        "\n",
        "  for i in range(0, num_steps * num_batches, num_steps):\n",
        "    X = Xs[:, i: i + num_steps]\n",
        "    Y = Ys[:, i: i + num_steps]\n",
        "    yield X, Y\n",
        "\n",
        "class SeqDataLoader:\n",
        "\n",
        "  def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
        "\n",
        "    if use_random_iter:\n",
        "      self.data_iter_fn = seq_data_iter_random\n",
        "    else:\n",
        "      self.data_iter_fn = seq_data_iter_sequential\n",
        "\n",
        "    self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
        "    self.batch_size, self.num_steps = batch_size, num_steps\n",
        "\n",
        "  def __iter__(self):\n",
        "\n",
        "    return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n",
        "\n",
        "def load_data_time_machine(batch_size, num_steps,\n",
        "                           use_random_iter=False, max_tokens=10000):\n",
        "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\n",
        "    data_iter = SeqDataLoader(\n",
        "        batch_size, num_steps, use_random_iter, max_tokens)\n",
        "    return data_iter, data_iter.vocab"
      ],
      "metadata": {
        "id": "oRvrkicuRqK-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, num_steps = 32, 35\n",
        "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
      ],
      "metadata": {
        "id": "nSiUta5oP3pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5559d1ea-fada-4e3e-add7-d3492d49fecf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/timemachine.txt from http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lstm_params(vocab_size, num_hiddens, device):\n",
        "\n",
        "  num_inputs = num_outputs = vocab_size\n",
        "  def normal(shape):\n",
        "    return torch.randn(size=shape, device=device)*0.01\n",
        "\n",
        "  def three():\n",
        "\n",
        "    return (normal((num_inputs, num_hiddens)),\n",
        "                normal((num_hiddens, num_hiddens)),\n",
        "                torch.zeros(num_hiddens, device=device))\n",
        "  \n",
        "  W_xi, W_hi, b_i = three()  # Input gate parameters\n",
        "  W_xf, W_hf, b_f = three()  # Forget gate parameters\n",
        "  W_xo, W_ho, b_o = three()  # Output gate parameters\n",
        "  W_xc, W_hc, b_c = three()  # Candidate memory cell parameters\n",
        "\n",
        "  W_hq = normal((num_hiddens, num_outputs))\n",
        "  b_q = torch.zeros(num_outputs, device=device)\n",
        "\n",
        "  params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,\n",
        "              b_c, W_hq, b_q]\n",
        "\n",
        "  for param in params:\n",
        "    param.requires_grad_(True)\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "38jc7GKOSEgb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_lstm_state(batch_size, num_hiddens, device):\n",
        "\n",
        "  return (torch.zeros((batch_size, num_hiddens), device=device), torch.zeros((batch_size, num_hiddens), device=device))"
      ],
      "metadata": {
        "id": "UESG4AbT9QiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm(inputs, state, params):\n",
        "\n",
        "  [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params\n",
        "  (H, C) = state\n",
        "  outputs = []\n",
        "\n",
        "  for X in inputs:\n",
        "    \n",
        "    I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)\n",
        "    F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)\n",
        "    O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)\n",
        "\n",
        "    C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)\n",
        "    C = F * C + I * C_tilda\n",
        "\n",
        "    H = O * torch.tanh(C)\n",
        "\n",
        "    Y = (H @ W_hq) + b_q\n",
        "    outputs.append(Y)\n",
        "\n",
        "  return torch.cat(outputs, dim=0), (H, C)"
      ],
      "metadata": {
        "id": "qu53z7l4_Iy3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModelScratch:\n",
        "\n",
        "  def __init__(self, vocab_size, num_hiddens, device,\n",
        "                 get_params, init_state, forward_fn):\n",
        "    self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
        "    self.params = get_params(vocab_size, num_hiddens, device)\n",
        "    self.init_state, self.forward_fn = init_state, forward_fn\n",
        "\n",
        "  def __call__(self, X, state):\n",
        "\n",
        "    X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
        "    return self.forward_fn(X, state, self.params)\n",
        "  \n",
        "  def begin_state(self, batch_size, device):\n",
        "    \n",
        "    return self.init_state(batch_size, self.num_hiddens, device)\n",
        "\n",
        "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
        "\n",
        "  state = net.begin_state(batch_size=1, device= device)\n",
        "  outputs = [vocab[prefix[0]]]\n",
        "  get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
        "  for y in prefix[1:]:\n",
        "    _, state = net(get_input(), state)\n",
        "    outputs.append(vocab[y])\n",
        "  \n",
        "  for _ in range(num_preds):\n",
        "    y, state = net(get_input(), state)\n",
        "    outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
        "\n",
        "  return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
        "\n",
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        params = [p for p in net.parameters() if p.requires_grad]\n",
        "    else:\n",
        "        params = net.params\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n",
        "\n",
        "class Timer:\n",
        "    \"\"\"Record multiple running times.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.start()\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the timer.\"\"\"\n",
        "        self.tik = time.time()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
        "        self.times.append(time.time() - self.tik)\n",
        "        return self.times[-1]\n",
        "\n",
        "    def avg(self):\n",
        "        \"\"\"Return the average time.\"\"\"\n",
        "        return sum(self.times) / len(self.times)\n",
        "\n",
        "    def sum(self):\n",
        "        \"\"\"Return the sum of time.\"\"\"\n",
        "        return sum(self.times)\n",
        "\n",
        "    def cumsum(self):\n",
        "        \"\"\"Return the accumulated time.\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()\n",
        "\n",
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "def sgd(params, lr, batch_size):\n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        for param in params:\n",
        "            param -= lr * param.grad / batch_size\n",
        "            param.grad.zero_()\n",
        "\n",
        "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
        "\n",
        "  state, timer = None, Timer()\n",
        "  metric = Accumulator(2)\n",
        "  for X, Y in train_iter:\n",
        "    if state is None or use_random_iter:\n",
        "      state = net.begin_state(batch_size=X.shape[0], device=device)\n",
        "    else:\n",
        "      if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
        "        state.detach_()\n",
        "      else:\n",
        "        for s in state:\n",
        "          s.detach_()\n",
        "    y = Y.T.reshape(-1)\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_hat, state = net(X, state)\n",
        "    l = loss(y_hat, y.long()).mean()\n",
        "    if isinstance(updater, torch.optim.Optimizer):\n",
        "      updater.zero_grad()\n",
        "      l.backward()\n",
        "      grad_clipping(net, 1)\n",
        "      updater.step()\n",
        "    else:\n",
        "      l.backward()\n",
        "      grad_clipping(net, 1)\n",
        "      updater(batch_size=1)\n",
        "    metric.add(l * y.numel(), y.numel())\n",
        "  return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n",
        "\n",
        "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
        "              use_random_iter=False):\n",
        "  \n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  if isinstance(net, nn.Module):\n",
        "    updater = torch.optim.SGD(net.parameters(), lr)\n",
        "  else:\n",
        "    updater = lambda batch_size: sgd(net.params, lr, batch_size)\n",
        "  \n",
        "  predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
        "\n",
        "  ui_x = []\n",
        "  ui_y = []\n",
        "  for epoch in range(num_epochs):\n",
        "    ppl, speed = train_epoch_ch8(\n",
        "            net, train_iter, loss, updater, device, use_random_iter)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      print(predict('time traveller'))\n",
        "      ui_x.append(epoch + 1)\n",
        "      ui_y.append(ppl)\n",
        "\n",
        "  \n",
        "  print(f'perplexity {ppl:.1f}, {speed:.1f} tokens/sec on {str(device)}')\n",
        "  print(predict('time traveller'))\n",
        "  print(predict('traveller'))\n",
        "\n",
        "  plt.plot(ui_x, ui_y, 'r')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "aCJWbQEWJOAK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, num_hiddens, device = len(vocab), 256, try_gpu()\n",
        "num_epochs, lr = 500, 1\n",
        "model = RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params,\n",
        "                            init_lstm_state, lstm)"
      ],
      "metadata": {
        "id": "ZTItYrHdI7Fb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "An4_6UpeJBYy",
        "outputId": "c22f22d1-35d1-44b1-93d9-4a241551c071"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time traveller                                                  \n",
            "time traveller                                                  \n",
            "time traveller  t t t t t t t t t t t t t t t t t t t t t t t t \n",
            "time traveller at at at at at at at at at at at at at at at at a\n",
            "time traveller at at at at at at at at at at at at at at at at a\n",
            "time traveller at an the the the the the the the the the the the\n",
            "time travellere the the the the the the the the the the the the \n",
            "time travellere the the the the the the the the the the the the \n",
            "time travellere the the the the the the the the the the the the \n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time travellerererererererererererererererererererererererererer\n",
            "time traveller an the the the the the the the the the the the th\n",
            "time traveller and the the the the the the the the the the the t\n",
            "time travellerererererererererererererererererererererererererer\n",
            "time traveller and the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller and the the the the the the the the the the the t\n",
            "time traveller and the there there are there and the there there\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the hime the time trove the time trove the ti\n",
            "time traveller and the the erat of the time traveller and the th\n",
            "time traveller the the treen the time traveller the the treen th\n",
            "time traveller the the that the that whis the time traveller the\n",
            "time traveller there insthen there and the time traveller there \n",
            "time traveller theed theed theed theed theed theed theed theed t\n",
            "time traveller the thing the time traveller the thing the time t\n",
            "time traveller and the time traveller and the time traveller and\n",
            "time traveller the thee than that is the thing time as int of th\n",
            "time traveller thinged and the that the gract a sumally the time\n",
            "time traveller this that he said the time traveller the that the\n",
            "time traveller thing his time traveller thing his time traveller\n",
            "time traveller three it i his in the thing the time traveller th\n",
            "time traveller this that seomethe thine so mont time is the germ\n",
            "time traveller this that or and the time travel con so dimension\n",
            "time traveller thin simint said the time traveller ther at i hiv\n",
            "time traveller andthen and that allimateesiot is thing sime the \n",
            "time traveller three are in on almous the eximent trime the tran\n",
            "time traveller moven tere at sacouness sover allarse the tire tr\n",
            "time traveller and why three dimensions and the time traveller t\n",
            "time traveller for so it rimensallenicmand has gringstire issome\n",
            "time traveller for so it in lide frat ex sill of the whyre ofes \n",
            "time traveller andthing a atile eropicalifay inthit sealle bur d\n",
            "time traveller for so it yimmlag thes it some and any of the thr\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller proceeded anyreal body must have extension in fou\n",
            "time traveller hermay is all draces of space but you cannotmove \n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "perplexity 1.1, 27012.1 tokens/sec on cuda:0\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "traveller pere fich rosthrian the ssce to move traveller ma\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}