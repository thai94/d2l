{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9.3.\u001ddeep_\u001drecurrent_neural_networks_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2K0fQ2P/BrKSKqoYovFRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thai94/d2l/blob/main/9.modern_recurrent_neural_networks/9_3_%1Ddeep_%1Drecurrent_neural_networks_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XF9ZaAR4J7lk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import collections\n",
        "import re\n",
        "import hashlib\n",
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch import nn\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_HUB = dict()\n",
        "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
        "DATA_HUB['time_machine'] = (DATA_URL + 'timemachine.txt',\n",
        "                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
        "\n",
        "def download(name, cache_dir=os.path.join('..', 'data')):\n",
        "    \"\"\"Download a file inserted into DATA_HUB, return the local filename.\"\"\"\n",
        "    assert name in DATA_HUB, f\"{name} does not exist in {DATA_HUB}.\"\n",
        "    url, sha1_hash = DATA_HUB[name]\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        sha1 = hashlib.sha1()\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "                sha1.update(data)\n",
        "        if sha1.hexdigest() == sha1_hash:\n",
        "            return fname  # Hit cache\n",
        "    print(f'Downloading {fname} from {url}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def download_extract(name, folder=None):\n",
        "    \"\"\"Download and extract a zip/tar file.\"\"\"\n",
        "    fname = download(name)\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    elif ext in ('.tar', '.gz'):\n",
        "        fp = tarfile.open(fname, 'r')\n",
        "    else:\n",
        "        assert False, 'Only zip/tar files can be extracted.'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\n",
        "\n",
        "def download_all():\n",
        "    \"\"\"Download all files in the DATA_HUB.\"\"\"\n",
        "    for name in DATA_HUB:\n",
        "        download(name)\n",
        "\n",
        "def read_time_machine():\n",
        "    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n",
        "    with open(download('time_machine'), 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
        "\n",
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def tokenize(lines, token='word'):\n",
        "\n",
        "  if token == 'word':\n",
        "    return [line.split() for line in lines]\n",
        "  elif token == 'char':\n",
        "    return [list(line) for line in lines]\n",
        "  else:\n",
        "    print('ERROR: unknow token type: ' + token)\n",
        "\n",
        "def count_corpus(tokens):\n",
        "\n",
        "  if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "   tokens = [token for line in tokens for token in line]\n",
        "  return collections.Counter(tokens)\n",
        "\n",
        "class Vocab:\n",
        "\n",
        "  def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "\n",
        "    if tokens is None:\n",
        "      tokens = []\n",
        "    if reserved_tokens is None:\n",
        "      reserved_tokens = []\n",
        "    counter = count_corpus(tokens)\n",
        "\n",
        "    self._token_freqs = sorted(counter.items(), key = lambda x: x[1], reverse=True)\n",
        "    self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "    self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
        "    for token, freq in self._token_freqs:\n",
        "      if freq < min_freq:\n",
        "        break;\n",
        "      if token not in self.token_to_idx:\n",
        "        self.idx_to_token.append(token)\n",
        "        self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)\n",
        "  \n",
        "  def __getitem__(self, tokens):\n",
        "    if not isinstance(tokens, (list, tuple)):\n",
        "      return self.token_to_idx.get(tokens, self.unk)\n",
        "    else:\n",
        "      return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "  def to_tokens(self, indices):\n",
        "    if not isinstance(indices, (list, tuple)):\n",
        "      return self.idx_to_token[indices]\n",
        "    else:\n",
        "      return [self.to_tokens(idx) for idx in indices]\n",
        "\n",
        "  @property\n",
        "  def unk(self):\n",
        "    return 0\n",
        "\n",
        "  @property\n",
        "  def token_freqs(self):\n",
        "    return self._token_freqs\n",
        "\n",
        "\n",
        "def load_corpus_time_machine(max_tokens=-1):\n",
        "\n",
        "  lines = read_time_machine()\n",
        "  tokens = tokenize(lines, 'char')\n",
        "  vocab = Vocab(tokens)\n",
        "\n",
        "  corpus = [vocab[token] for line in tokens for token in line]\n",
        "  if max_tokens > 0:\n",
        "    corpus = corpus[:max_tokens]\n",
        "  return corpus, vocab\n",
        "\n",
        "\n",
        "def seq_data_iter_random(corpus, batch_size, num_steps):\n",
        "\n",
        "  corpos = corpus[random.randint(0, num_steps - 1):]\n",
        "  num_subseqs = (len(corpos) - 1) // num_steps\n",
        "  initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
        "  random.shuffle(initial_indices)\n",
        "\n",
        "  def data(pos):\n",
        "    return corpus[pos: pos + num_steps]\n",
        "  \n",
        "  num_batches = num_subseqs // batch_size\n",
        "\n",
        "  for i in range(0, batch_size * num_batches, batch_size):\n",
        "    initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
        "    X = [data(idx) for idx in initial_indices_per_batch]\n",
        "    Y = [data(idx + 1) for idx in initial_indices_per_batch]\n",
        "    yield torch.tensor(X), torch.tensor(Y)\n",
        "\n",
        "\n",
        "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
        "\n",
        "  offset = random.randint(0, num_steps)\n",
        "  num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
        "  Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
        "  Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
        "\n",
        "  Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
        "  num_batches = Xs.shape[1] // num_steps\n",
        "\n",
        "  for i in range(0, num_steps * num_batches, num_steps):\n",
        "    X = Xs[:, i: i + num_steps]\n",
        "    Y = Ys[:, i: i + num_steps]\n",
        "    yield X, Y\n",
        "\n",
        "class SeqDataLoader:\n",
        "\n",
        "  def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
        "\n",
        "    if use_random_iter:\n",
        "      self.data_iter_fn = seq_data_iter_random\n",
        "    else:\n",
        "      self.data_iter_fn = seq_data_iter_sequential\n",
        "\n",
        "    self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
        "    self.batch_size, self.num_steps = batch_size, num_steps\n",
        "\n",
        "  def __iter__(self):\n",
        "\n",
        "    return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n",
        "\n",
        "def load_data_time_machine(batch_size, num_steps,\n",
        "                           use_random_iter=False, max_tokens=10000):\n",
        "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\n",
        "    data_iter = SeqDataLoader(\n",
        "        batch_size, num_steps, use_random_iter, max_tokens)\n",
        "    return data_iter, data_iter.vocab"
      ],
      "metadata": {
        "id": "H3lzwo6dLQl-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, num_steps = 32, 35\n",
        "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
      ],
      "metadata": {
        "id": "6Eb1Owl0KwQ-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    \"\"\"The RNN model.\"\"\"\n",
        "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
        "        super(RNNModel, self).__init__(**kwargs)\n",
        "        self.rnn = rnn_layer\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_hiddens = self.rnn.hidden_size\n",
        "        # If the RNN is bidirectional (to be introduced later),\n",
        "        # `num_directions` should be 2, else it should be 1.\n",
        "        if not self.rnn.bidirectional:\n",
        "            self.num_directions = 1\n",
        "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
        "        else:\n",
        "            self.num_directions = 2\n",
        "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
        "\n",
        "    def forward(self, inputs, state):\n",
        "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
        "        X = X.to(torch.float32)\n",
        "        Y, state = self.rnn(X, state)\n",
        "        # The fully connected layer will first change the shape of `Y` to\n",
        "        # (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is\n",
        "        # (`num_steps` * `batch_size`, `vocab_size`).\n",
        "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
        "        return output, state\n",
        "\n",
        "    def begin_state(self, device, batch_size=1):\n",
        "        if not isinstance(self.rnn, nn.LSTM):\n",
        "            # `nn.GRU` takes a tensor as hidden state\n",
        "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
        "                                 batch_size, self.num_hiddens),\n",
        "                                device=device)\n",
        "        else:\n",
        "            # `nn.LSTM` takes a tuple of hidden states\n",
        "            return (torch.zeros((\n",
        "                self.num_directions * self.rnn.num_layers,\n",
        "                batch_size, self.num_hiddens), device=device),\n",
        "                    torch.zeros((\n",
        "                        self.num_directions * self.rnn.num_layers,\n",
        "                        batch_size, self.num_hiddens), device=device))\n",
        "class RNNModelScratch:\n",
        "\n",
        "  def __init__(self, vocab_size, num_hiddens, device,\n",
        "                 get_params, init_state, forward_fn):\n",
        "    self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
        "    self.params = get_params(vocab_size, num_hiddens, device)\n",
        "    self.init_state, self.forward_fn = init_state, forward_fn\n",
        "\n",
        "  def __call__(self, X, state):\n",
        "\n",
        "    X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
        "    return self.forward_fn(X, state, self.params)\n",
        "  \n",
        "  def begin_state(self, batch_size, device):\n",
        "    \n",
        "    return self.init_state(batch_size, self.num_hiddens, device)\n",
        "\n",
        "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
        "\n",
        "  state = net.begin_state(batch_size=1, device= device)\n",
        "  outputs = [vocab[prefix[0]]]\n",
        "  get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
        "  for y in prefix[1:]:\n",
        "    _, state = net(get_input(), state)\n",
        "    outputs.append(vocab[y])\n",
        "  \n",
        "  for _ in range(num_preds):\n",
        "    y, state = net(get_input(), state)\n",
        "    outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
        "\n",
        "  return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
        "\n",
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        params = [p for p in net.parameters() if p.requires_grad]\n",
        "    else:\n",
        "        params = net.params\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n",
        "\n",
        "class Timer:\n",
        "    \"\"\"Record multiple running times.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.start()\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the timer.\"\"\"\n",
        "        self.tik = time.time()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
        "        self.times.append(time.time() - self.tik)\n",
        "        return self.times[-1]\n",
        "\n",
        "    def avg(self):\n",
        "        \"\"\"Return the average time.\"\"\"\n",
        "        return sum(self.times) / len(self.times)\n",
        "\n",
        "    def sum(self):\n",
        "        \"\"\"Return the sum of time.\"\"\"\n",
        "        return sum(self.times)\n",
        "\n",
        "    def cumsum(self):\n",
        "        \"\"\"Return the accumulated time.\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()\n",
        "\n",
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "def sgd(params, lr, batch_size):\n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        for param in params:\n",
        "            param -= lr * param.grad / batch_size\n",
        "            param.grad.zero_()\n",
        "\n",
        "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
        "\n",
        "  state, timer = None, Timer()\n",
        "  metric = Accumulator(2)\n",
        "  for X, Y in train_iter:\n",
        "    if state is None or use_random_iter:\n",
        "      state = net.begin_state(batch_size=X.shape[0], device=device)\n",
        "    else:\n",
        "      if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
        "        state.detach_()\n",
        "      else:\n",
        "        for s in state:\n",
        "          s.detach_()\n",
        "    y = Y.T.reshape(-1)\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_hat, state = net(X, state)\n",
        "    l = loss(y_hat, y.long()).mean()\n",
        "    if isinstance(updater, torch.optim.Optimizer):\n",
        "      updater.zero_grad()\n",
        "      l.backward()\n",
        "      grad_clipping(net, 1)\n",
        "      updater.step()\n",
        "    else:\n",
        "      l.backward()\n",
        "      grad_clipping(net, 1)\n",
        "      updater(batch_size=1)\n",
        "    metric.add(l * y.numel(), y.numel())\n",
        "  return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n",
        "\n",
        "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
        "              use_random_iter=False):\n",
        "  \n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  if isinstance(net, nn.Module):\n",
        "    updater = torch.optim.SGD(net.parameters(), lr)\n",
        "  else:\n",
        "    updater = lambda batch_size: sgd(net.params, lr, batch_size)\n",
        "  \n",
        "  predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
        "\n",
        "  ui_x = []\n",
        "  ui_y = []\n",
        "  for epoch in range(num_epochs):\n",
        "    ppl, speed = train_epoch_ch8(\n",
        "            net, train_iter, loss, updater, device, use_random_iter)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      print(predict('time traveller'))\n",
        "      ui_x.append(epoch + 1)\n",
        "      ui_y.append(ppl)\n",
        "\n",
        "  \n",
        "  print(f'perplexity {ppl:.1f}, {speed:.1f} tokens/sec on {str(device)}')\n",
        "  print(predict('time traveller'))\n",
        "  print(predict('traveller'))\n",
        "\n",
        "  plt.plot(ui_x, ui_y, 'r')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "cDyUXXqtLnr6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, num_hiddens, num_layers = len(vocab), 256, 2\n",
        "num_inputs = vocab_size\n",
        "device = try_gpu()\n",
        "lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)\n",
        "model = RNNModel(lstm_layer, len(vocab))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "W30fEsllLUfF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs, lr = 500, 2\n",
        "train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xYVEjoR0Ltpq",
        "outputId": "84aba3b9-c30a-4cd0-9229-d5a48700ba71"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time traveller                                                  \n",
            "time traveller                                                  \n",
            "time traveller                                                  \n",
            "time traveller ta ae a ae a ae a ae a ae a ae a ae a ae a ae a a\n",
            "time traveller aa te aa te aa te aa te aa te aa te aa te aa te a\n",
            "time travellere the the the the the the the the the the the the \n",
            "time traveller an the the the the the the the the the the the th\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time travellere the the the the the the the the the the the the \n",
            "time traveller the the the the the the the the the the the the t\n",
            "time travellere the the the the the the the the the the the the \n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller thing this than the trove traveller thing this th\n",
            "time traveller thing that thathersance thing that thathersance t\n",
            "time traveller the thing that that that that that that that that\n",
            "time traveller the time traveller the time traveller the time tr\n",
            "time traveller thick a sealler this this that is thisk of the ti\n",
            "time traveller that the promed and suchaning said the merical ma\n",
            "time travellerit whowwing thit is all the three dimensions of th\n",
            "time travellerit s all they thimk as mere is the time travelleri\n",
            "time traveller three dimensions thin whe sool dimensions thin wh\n",
            "time traveller proceeded anyreal body must have extension in fou\n",
            "time traveller proceeded anyreal body must have extension in fou\n",
            "time traveller smiled frees you can go backward and forward free\n",
            "time travellerit s against reason said filbywan a cube that does\n",
            "time traveller proceeded anyreal body must have extension in fou\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will beccodeniely freeidite brared that\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "perplexity 1.0, 79878.4 tokens/sec on cuda:0\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "travelleryou can show black is white by argument said filby\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}