{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.6.implementation_of_softmax_regression_from_\u001dscratch_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/UFIrv4l0NoWw51sVKDnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thai94/d2l/blob/main/3.linear-neural-networks/3_6_implementation_of_softmax_regression_from_%1Dscratch_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "COS3dkxvnw-O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_fashion_mnist(batch_size, resize=None):\n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
        "    mnist_train, mnist_test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    # Divide all numbers by 255 so that all pixel values are between\n",
        "    # 0 and 1, add a batch dimension at the last. And cast label to int32\n",
        "    process = lambda X, y: (tf.expand_dims(X, axis=3) / 255,\n",
        "                            tf.cast(y, dtype='int32'))\n",
        "    resize_fn = lambda X, y: (\n",
        "        tf.image.resize_with_pad(X, resize, resize) if resize else X, y)\n",
        "    return (\n",
        "        tf.data.Dataset.from_tensor_slices(process(*mnist_train)).batch(\n",
        "            batch_size).shuffle(len(mnist_train[0])).map(resize_fn),\n",
        "        tf.data.Dataset.from_tensor_slices(process(*mnist_test)).batch(\n",
        "            batch_size).map(resize_fn))"
      ],
      "metadata": {
        "id": "QWULB7sQo3b5"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
      ],
      "metadata": {
        "id": "1GBscbb0oyuj"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "\n",
        "W = tf.Variable(tf.random.normal(shape=(num_inputs, num_outputs), mean=0, stddev=0.01))\n",
        "b = tf.Variable(tf.zeros(num_outputs))"
      ],
      "metadata": {
        "id": "iGSal53No56w"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(X):\n",
        "  X_exp = tf.exp(X)\n",
        "  partition = tf.reduce_sum(X_exp, 1, keepdims=True)\n",
        "  return X_exp / partition"
      ],
      "metadata": {
        "id": "DpxUOA9HsH9m"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def net(X):\n",
        "  return softmax(tf.matmul(tf.reshape(X, (-1, W.shape[0])), W) + b)"
      ],
      "metadata": {
        "id": "cK1r8L6csapF"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_hat, y):\n",
        "    return -tf.math.log(tf.boolean_mask(\n",
        "        y_hat, tf.one_hot(y, depth=y_hat.shape[-1])))"
      ],
      "metadata": {
        "id": "kLt9PLeVuCwi"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = tf.constant([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
        "y = tf.constant([0, 2])\n",
        "cross_entropy(y_hat, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3We-HcOz04A",
        "outputId": "fb724a8d-67da-4bfa-93cf-0f0f1cd593d9"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2.3025851, 0.6931472], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = tf.argmax(y_hat, axis=1)\n",
        "    cmp = tf.cast(y_hat, y.dtype) == y\n",
        "    return float(tf.reduce_sum(tf.cast(cmp, y.dtype)))"
      ],
      "metadata": {
        "id": "t9hUhothuK0P"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(net, data_iter):\n",
        "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
        "    metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
        "    for X, y in data_iter:\n",
        "        metric.add(accuracy(net(X), y), len(y))\n",
        "    return metric[0] / metric[1]"
      ],
      "metadata": {
        "id": "EkHGUJDMuZtL"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "id": "vmvKkKAdvH3o"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_ch3(net, train_iter, loss, updater, params, lr):\n",
        "  metric = Accumulator(3)\n",
        "  for X, y in train_iter:\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_hat = net(X)\n",
        "      l = loss(y_hat, y)\n",
        "    \n",
        "    updater(X.shape[0], tape.gradient(l, params), params, lr)\n",
        "    l_sum = tf.reduce_sum(l)\n",
        "    metric.add(l_sum, accuracy(y_hat, y), tf.size(y))\n",
        "  return metric[0] / metric[2], metric[1] / metric[2]"
      ],
      "metadata": {
        "id": "VdbPo9NgvJw5"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater, params, lr):\n",
        "  for epoch in range(num_epochs):\n",
        "    train_metrics = train_epoch_ch3(net, train_iter, loss, updater, params, lr)\n",
        "    test_acc = evaluate_accuracy(net, test_iter)\n",
        "    print('epoch: %s' % epoch)\n",
        "    print(train_metrics)\n",
        "    print(test_acc)\n",
        "  train_loss, train_acc = train_metrics"
      ],
      "metadata": {
        "id": "YV8egKLFx6yw"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(params, grads, lr, batch_size):\n",
        "    for param, grad in zip(params, grads):\n",
        "        param.assign_sub(lr*grad/batch_size)"
      ],
      "metadata": {
        "id": "d5EwAjo9yia4"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updater(batch_size, grads, params, lr): \n",
        "  sgd(params, grads, lr, batch_size)"
      ],
      "metadata": {
        "id": "vAbekXz1yP1v"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "lr = 0.01\n",
        "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater, [W, b], lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV-kSuxVy2OY",
        "outputId": "315018c1-365c-4d0d-e6da-983e0d909a0d"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "(1.3711719393412272, 0.6414333333333333)\n",
            "0.6809\n",
            "epoch: 1\n",
            "(0.9178400165557862, 0.7162333333333334)\n",
            "0.7239\n",
            "epoch: 2\n",
            "(0.8033531344095866, 0.75105)\n",
            "0.7474\n",
            "epoch: 3\n",
            "(0.742962868754069, 0.7679)\n",
            "0.7588\n",
            "epoch: 4\n",
            "(0.7032462577819825, 0.77935)\n",
            "0.7714\n",
            "epoch: 5\n",
            "(0.6744265129089355, 0.7885833333333333)\n",
            "0.7775\n",
            "epoch: 6\n",
            "(0.6521441453297933, 0.7951333333333334)\n",
            "0.7825\n",
            "epoch: 7\n",
            "(0.6340786262512207, 0.7996333333333333)\n",
            "0.7885\n",
            "epoch: 8\n",
            "(0.6191635148366292, 0.8029)\n",
            "0.7914\n",
            "epoch: 9\n",
            "(0.6064373116811117, 0.80595)\n",
            "0.7954\n",
            "epoch: 10\n",
            "(0.5955943726857503, 0.8093)\n",
            "0.7982\n",
            "epoch: 11\n",
            "(0.5860953343073527, 0.8118)\n",
            "0.8011\n",
            "epoch: 12\n",
            "(0.577628319422404, 0.8142333333333334)\n",
            "0.8036\n",
            "epoch: 13\n",
            "(0.5700759317398071, 0.8165333333333333)\n",
            "0.8052\n",
            "epoch: 14\n",
            "(0.5632773867289226, 0.8184666666666667)\n",
            "0.8072\n",
            "epoch: 15\n",
            "(0.557164646021525, 0.8199)\n",
            "0.8083\n",
            "epoch: 16\n",
            "(0.5514022529602051, 0.8218333333333333)\n",
            "0.809\n",
            "epoch: 17\n",
            "(0.5463516469319661, 0.8231833333333334)\n",
            "0.8107\n",
            "epoch: 18\n",
            "(0.5416445468266805, 0.8247166666666667)\n",
            "0.8115\n",
            "epoch: 19\n",
            "(0.5372456940968832, 0.8256166666666667)\n",
            "0.8129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in test_iter:\n",
        "  break"
      ],
      "metadata": {
        "id": "Jqk8gegy1467"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.argmax(net(X), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEPUxTU12IlG",
        "outputId": "cbfdfabb-993e-4845-bc95-d0122f777c9e"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256,), dtype=int64, numpy=\n",
              "array([9, 2, 1, 1, 6, 1, 4, 6, 7, 7, 4, 5, 5, 3, 4, 1, 2, 6, 8, 0, 0, 7,\n",
              "       7, 5, 1, 2, 6, 3, 9, 4, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 0, 1, 3, 9,\n",
              "       6, 7, 2, 1, 4, 6, 6, 2, 7, 6, 4, 2, 8, 2, 8, 0, 7, 7, 8, 5, 1, 1,\n",
              "       3, 4, 7, 8, 7, 0, 6, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2,\n",
              "       0, 6, 5, 3, 6, 7, 1, 8, 0, 1, 6, 2, 3, 6, 7, 2, 7, 8, 7, 9, 9, 4,\n",
              "       2, 5, 7, 0, 5, 2, 8, 4, 7, 8, 0, 0, 9, 9, 3, 0, 8, 4, 1, 5, 4, 1,\n",
              "       9, 1, 8, 4, 6, 1, 2, 5, 1, 0, 0, 0, 1, 6, 1, 3, 2, 2, 6, 6, 1, 3,\n",
              "       5, 0, 4, 7, 9, 3, 7, 2, 3, 9, 0, 9, 4, 7, 4, 2, 6, 5, 2, 1, 2, 1,\n",
              "       3, 0, 9, 1, 0, 9, 3, 8, 7, 9, 9, 4, 4, 7, 1, 2, 1, 6, 3, 2, 8, 3,\n",
              "       6, 1, 1, 0, 2, 9, 2, 4, 0, 7, 9, 8, 4, 1, 8, 4, 1, 3, 1, 2, 7, 4,\n",
              "       8, 5, 6, 0, 7, 7, 6, 6, 7, 0, 7, 8, 9, 2, 9, 0, 5, 1, 4, 2, 5, 4,\n",
              "       9, 6, 2, 8, 6, 4, 2, 4, 9, 7, 4, 5, 5, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuAOR3CT2WAD",
        "outputId": "3273f6b7-2da0-44b5-ebe7-456d80bb50a7"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256,), dtype=int32, numpy=\n",
              "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5,\n",
              "       7, 9, 1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7,\n",
              "       6, 7, 2, 1, 2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1,\n",
              "       2, 3, 9, 8, 7, 0, 2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2,\n",
              "       0, 6, 5, 3, 6, 7, 1, 8, 0, 1, 4, 2, 3, 6, 7, 2, 7, 8, 5, 9, 9, 4,\n",
              "       2, 5, 7, 0, 5, 2, 8, 6, 7, 8, 0, 0, 9, 9, 3, 0, 8, 4, 1, 5, 4, 1,\n",
              "       9, 1, 8, 6, 2, 1, 2, 5, 1, 0, 0, 0, 1, 6, 1, 6, 2, 2, 4, 4, 1, 4,\n",
              "       5, 0, 4, 7, 9, 3, 7, 2, 3, 9, 0, 9, 4, 7, 4, 2, 0, 5, 2, 1, 2, 1,\n",
              "       3, 0, 9, 1, 0, 9, 3, 6, 7, 9, 9, 4, 4, 7, 1, 2, 1, 6, 3, 2, 8, 3,\n",
              "       6, 1, 1, 0, 2, 9, 2, 4, 0, 7, 9, 8, 4, 1, 8, 4, 1, 3, 1, 6, 7, 2,\n",
              "       8, 5, 2, 0, 7, 7, 6, 2, 7, 0, 7, 8, 9, 2, 9, 0, 5, 1, 4, 4, 5, 6,\n",
              "       9, 2, 6, 8, 6, 4, 2, 2, 9, 7, 6, 5, 5, 2], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    }
  ]
}