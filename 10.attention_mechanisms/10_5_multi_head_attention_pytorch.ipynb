{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.5.multi_head_attention_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbCSlagpnCdLhrkeqhORdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thai94/d2l/blob/main/10.attention_mechanisms/10_5_multi_head_attention_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw7DPWjdJ0mU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 num_heads, dropout, bias=False, **kwargs):\n",
        "    \n",
        "    super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "    self.num_heads = num_heads\n",
        "    self.attention = DotProductAttention(dropout)\n",
        "    self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
        "    self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
        "    self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
        "    self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
        "\n",
        "  def forward(self, queries, keys, values, valid_lens):\n",
        "\n",
        "    queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
        "    keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
        "    values = transpose_qkv(self.W_v(values), self.num_heads)\n",
        "    if valid_lens is not None:\n",
        "      valid_lens = torch.repeat_interleave(\n",
        "                valid_lens, repeats=self.num_heads, dim=0)\n",
        "      \n",
        "    output = self.attention(queries, keys, values, valid_lens)\n",
        "    output_concat = transpose_output(output, self.num_heads)\n",
        "    return self.W_o(output_concat)"
      ],
      "metadata": {
        "id": "4uV0l1DYKRG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose_qkv(X, num_heads):\n",
        "    \"\"\"Transposition for parallel computation of multiple attention heads.\"\"\"\n",
        "    # Shape of input `X`:\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`).\n",
        "    # Shape of output `X`:\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_heads`,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
        "\n",
        "    # Shape of output `X`:\n",
        "    # (`batch_size`, `num_heads`, no. of queries or key-value pairs,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    X = X.permute(0, 2, 1, 3)\n",
        "\n",
        "    # Shape of `output`:\n",
        "    # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    return X.reshape(-1, X.shape[2], X.shape[3])"
      ],
      "metadata": {
        "id": "PLU4yHx2DtOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose_output(X, num_heads):\n",
        "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
        "    X = X.permute(0, 2, 1, 3)\n",
        "    return X.reshape(X.shape[0], X.shape[1], -1)"
      ],
      "metadata": {
        "id": "UMBJ2RyXDv3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_hiddens, num_heads = 100, 5\n",
        "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n",
        "                               num_hiddens, num_heads, 0.5)\n",
        "attention.eval()"
      ],
      "metadata": {
        "id": "yRaJMk5iD0hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, num_queries, num_kvpairs, valid_lens = 2, 4, 6, torch.tensor([3, 2])\n",
        "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
        "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
        "attention(X, Y, Y, valid_lens).shape"
      ],
      "metadata": {
        "id": "rmRqZm78D2rE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}